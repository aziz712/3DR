{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xMa2YZ2o6Og2"
      },
      "outputs": [],
      "source": [
        "# Monter Google Drive pour sauvegarder les modèles\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Installer PyTorch et autres bibliothèques nécessaires\n",
        "#!pip install torch torchvision numpy matplotlib\n",
        "#!pip install trimesh\n",
        "#!pip install tqdm\n",
        "\n",
        "\n",
        "# Télécharger et extraire le dataset Pix3D\n",
        "\n",
        "!wget http://pix3d.csail.mit.edu/data/pix3d.zip\n",
        "!unzip pix3d.zip && rm pix3d.zip\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Importation des bibliothèques nécessaires:**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "### Nous commençons par importer toutes les bibliothèques nécessaires pour le traitement des données, la gestion des modèles, et la manipulation des fichiers."
      ],
      "metadata": {
        "id": "niGJ6G8uqmRV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importation des bibliothèques nécessaires\n",
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import scipy.io as sio  # Pour charger les fichiers .mat\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "from PIL import Image  # Charger l'image using PIL instead of matplotlib\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "\n",
        "# Configuration de l'appareil (GPU ou CPU)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Utilisation de l'appareil : {device}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6OpsEMKEqNRM",
        "outputId": "e99a754a-9f1f-4181-f1a2-b36fb114eeb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Utilisation de l'appareil : cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Étape 2 : Définition du Dataset Pix3D**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "### Classe Pix3DDataset :\n",
        "#### Cette classe permet de charger les images 2D, masques, voxels, keypoints, et les modèles 3D basés sur le fichier JSON."
      ],
      "metadata": {
        "id": "qZpnPX_8q0fN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Pix3DDataset(Dataset):\n",
        "    def __init__(self, dataset_path, json_file, transform=None):\n",
        "        self.dataset_path = Path(dataset_path)\n",
        "        self.json_file = self.dataset_path / json_file\n",
        "        self.transform = transform\n",
        "        self.data = self.load_metadata()\n",
        "\n",
        "    def load_metadata(self):\n",
        "        \"\"\"Charge les métadonnées depuis le fichier JSON.\"\"\"\n",
        "        with open(self.json_file, 'r') as f:\n",
        "            metadata = json.load(f)\n",
        "        data = []\n",
        "        for entry in metadata:\n",
        "            img_path = self.dataset_path / entry['img']\n",
        "            mask_path = self.dataset_path / entry['mask']\n",
        "            model_path = self.dataset_path / entry['model']\n",
        "            voxel_path = self.dataset_path / entry['voxel']\n",
        "            keypoint_path = self.dataset_path / entry['3d_keypoints']\n",
        "            if img_path.exists() and model_path.exists():\n",
        "                data.append({\n",
        "                    'img': img_path,\n",
        "                    'mask': mask_path,\n",
        "                    'model': model_path,\n",
        "                    'voxel': voxel_path,\n",
        "                    'keypoints': keypoint_path\n",
        "                })\n",
        "        return data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        entry = self.data[idx]\n",
        "        img = Image.open(entry['img']).convert('RGB')  # Assurer que l'image est en format RGB\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        # Charger le masque (si disponible)\n",
        "        mask = Image.open(entry['mask']).convert('L') if entry['mask'].exists() else None\n",
        "        if self.transform and mask is not None:\n",
        "            mask = self.transform(mask)\n",
        "\n",
        "        # Charger les voxels (format .mat)\n",
        "        voxel = sio.loadmat(entry['voxel'])['voxel'] if entry['voxel'].exists() else None\n",
        "\n",
        "        # Charger les keypoints 3D\n",
        "        keypoints = np.loadtxt(entry['keypoints']) if entry['keypoints'].exists() else None\n",
        "\n",
        "        return {\n",
        "            'img': img,\n",
        "            'mask': mask,\n",
        "            'voxel': voxel,\n",
        "            'keypoints': keypoints,\n",
        "            'model': entry['model']\n",
        "        }\n"
      ],
      "metadata": {
        "id": "Qz-hTR2_q2jW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### La fonction `collate_fn` est utilisée pour préparer les données lors de la création de batches dans un DataLoader personnalisé en PyTorch.Cette fonction est essentielle pour manipuler des données de tailles variables dans des modèles de deep learning.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "# **Objectif**\n",
        "#### Elle combine les données d'un batch en les rendant compatibles, en particulier en ajoutant un padding uniforme aux keypoints (points clés) pour garantir que toutes les entrées ont la même taille."
      ],
      "metadata": {
        "id": "BzrpyfkGa-FB"
      }
    },
    {
      "source": [
        "def collate_fn(batch):\n",
        "    \"\"\"Fonction pour combiner les éléments d'un batch et ajouter un padding aux keypoints.\"\"\"\n",
        "    max_keypoints = max([len(d['keypoints']) for d in batch if d['keypoints'] is not None])\n",
        "\n",
        "    keypoints = []\n",
        "    for d in batch:\n",
        "        if d['keypoints'] is not None:\n",
        "            padded_keypoints = torch.cat([torch.tensor(d['keypoints']), torch.zeros(max_keypoints - len(d['keypoints']), 3)], dim=0)\n",
        "            keypoints.append(padded_keypoints)\n",
        "        else:\n",
        "            keypoints.append(torch.zeros(max_keypoints, 3))  # Padding complet si aucun keypoint\n",
        "\n",
        "    keypoints = torch.stack(keypoints)\n",
        "\n",
        "    return {\n",
        "        'img': torch.stack([d['img'] for d in batch]),\n",
        "        'mask': torch.stack([d['mask'] for d in batch]) if batch[0]['mask'] is not None else None,\n",
        "        'voxel': torch.stack([torch.tensor(d['voxel'], dtype=torch.float32) for d in batch]),\n",
        "        'keypoints': keypoints,\n",
        "        'model': [d['model'] for d in batch]\n",
        "    }\n"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "nbhZOvfmw679"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Étape 3 : Définition des modèles GAN**\n",
        "\n",
        "---\n",
        "\n",
        "## **Générateur :**\n",
        "\n",
        "### Le générateur prend une image 2D en entrée et produit un volume 3D"
      ],
      "metadata": {
        "id": "2jnc_mPXq6GU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Generator, self).__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, 4, stride=2, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64, 128, 4, stride=2, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(128, 256, 4, stride=2, padding=1),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.fc = nn.Linear(256 * 8 * 8, 32 * 32 * 32)\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.ConvTranspose3d(1, 64, 4, stride=2, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose3d(64, 1, 4, stride=2, padding=1),  # Changez 1 en 16 si vous voulez plusieurs canaux\n",
        "            nn.Tanh()  # Ou une autre fonction d'activation appropriée\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = self.encoder(x)\n",
        "        flat = features.view(features.size(0), -1)\n",
        "        volume = self.fc(flat).view(-1, 1, 32, 32, 32)  # Changez 1 en 16 si vous voulez plusieurs canaux\n",
        "        output = self.decoder(volume)\n",
        "        return output\n"
      ],
      "metadata": {
        "id": "1GAm7Dguq_3F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Discriminateur**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "### Le discriminateur évalue si un volume 3D est réel ou généré."
      ],
      "metadata": {
        "id": "J_Cv48PRrCd0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv3d(1, 64, kernel_size=4, stride=2, padding=1), # Changed input channels to 1\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv3d(64, 128, kernel_size=4, stride=2, padding=1),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv3d(128, 256, kernel_size=4, stride=2, padding=1),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv3d(256, 512, kernel_size=4, stride=2, padding=1),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv3d(512, 1, kernel_size=4, stride=2, padding=1),\n",
        "        )\n",
        "        self.fc = nn.Linear(4*4*4, 1)  # Adjusted linear layer input size to match flattened output\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.net(x)\n",
        "        #print(f\"Forme avant flatten: {out.shape}\")\n",
        "        out = out.view(out.size(0), -1)  # Flatten\n",
        "        #print(f\"Forme après flatten: {out.shape}\")\n",
        "        out = self.fc(out)\n",
        "        out = torch.sigmoid(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "fIbbFovBrFic"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Étape 4 :**\n",
        "---\n",
        "### Fonction pour sauvegarder des modèles 3D au format .obj\n",
        "\n"
      ],
      "metadata": {
        "id": "RTB27qRfrHal"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def save_as_obj(voxel, file_path):\n",
        "    \"\"\"Sauvegarde un volume voxelisé en format .obj.\"\"\"\n",
        "    voxel = voxel.squeeze().cpu().numpy()  # Convertir en NumPy\n",
        "    with open(file_path, 'w') as f:\n",
        "        for x in range(voxel.shape[0]):\n",
        "            for y in range(voxel.shape[1]):\n",
        "                for z in range(voxel.shape[2]):\n",
        "                    if voxel[x, y, z] > 0.5:  # Seuil pour considérer comme occupé\n",
        "                        f.write(f\"v {x} {y} {z}\\n\")\n"
      ],
      "metadata": {
        "id": "bRuCgnVDrKc8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Étape 5 :**\n",
        "---\n",
        "## Boucle d’entraînement\n"
      ],
      "metadata": {
        "id": "rrIGlX4IrL7N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialisation\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "G = Generator().to(device)\n",
        "D = Discriminator().to(device)\n",
        "criterion = nn.BCELoss()\n",
        "optimizer_G = optim.Adam(G.parameters(), lr=0.0002)\n",
        "optimizer_D = optim.Adam(D.parameters(), lr=0.0002)\n",
        "\n",
        "# Charger le dataset\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Resize((64, 64)),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "dataset = Pix3DDataset('/content/pix3d', 'pix3d.json', transform=transform)\n",
        "dataloader = DataLoader(dataset, batch_size=8, shuffle=True, collate_fn=collate_fn)\n",
        "\n",
        "# Chemins pour sauvegarder les modèles et les logs\n",
        "output_dir = './output_models'\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "log_file = os.path.join(output_dir, 'training_logs.txt')\n",
        "\n",
        "# Initialisation du fichier de log\n",
        "with open(log_file, 'w') as f:\n",
        "    f.write(\"Epoch\\tD_Loss\\tG_Loss\\n\")\n",
        "\n",
        "# Réduction des besoins en ressources et des logs\n",
        "num_epochs = 5\n",
        "for epoch in range(num_epochs):\n",
        "    print(f\"Époque {epoch + 1}/{num_epochs}\")\n",
        "    epoch_d_loss, epoch_g_loss = 0.0, 0.0\n",
        "    for i, batch in enumerate(dataloader):\n",
        "        # Chargement des données\n",
        "        real_images = batch['img'].to(device)\n",
        "        real_voxels = batch['voxel'].to(device).float().unsqueeze(1)\n",
        "\n",
        "        # Vérifiez les dimensions des données\n",
        "        assert real_images.dim() == 4, f\"Problème avec real_images : {real_images.shape}\"\n",
        "        assert real_voxels.dim() == 5, f\"Problème avec real_voxels : {real_voxels.shape}\"\n",
        "\n",
        "        # Mise à jour du discriminateur\n",
        "        optimizer_D.zero_grad()\n",
        "        real_labels = torch.ones(real_images.size(0), 1).to(device)\n",
        "        fake_labels = torch.zeros(real_images.size(0), 1).to(device)\n",
        "\n",
        "        # Perte réelle\n",
        "        outputs_real = D(real_voxels)\n",
        "        d_loss_real = criterion(outputs_real, real_labels)\n",
        "\n",
        "        # Perte fausse\n",
        "        with torch.no_grad():\n",
        "            fake_voxels = G(real_images)\n",
        "        outputs_fake = D(fake_voxels.detach())\n",
        "        d_loss_fake = criterion(outputs_fake, fake_labels)\n",
        "\n",
        "        # Mise à jour\n",
        "        d_loss = d_loss_real + d_loss_fake\n",
        "        d_loss.backward()\n",
        "        optimizer_D.step()\n",
        "\n",
        "        # Mise à jour du générateur\n",
        "        optimizer_G.zero_grad()\n",
        "        outputs_fake = D(fake_voxels)\n",
        "        g_loss = criterion(outputs_fake, real_labels)\n",
        "\n",
        "        # Diagnostic avant le calcul des gradients\n",
        "        assert not torch.isnan(g_loss), \"g_loss contient NaN\"\n",
        "        g_loss.backward()\n",
        "        optimizer_G.step()\n",
        "\n",
        "        # Suivi des pertes\n",
        "        epoch_d_loss += d_loss.item()\n",
        "        epoch_g_loss += g_loss.item()\n",
        "\n",
        "        if (i + 1) % 50 == 0:  # Log moins souvent\n",
        "            print(f\"Époque [{epoch+1}/{num_epochs}], Étape [{i+1}/{len(dataloader)}], \"\n",
        "                  f\"D_Loss: {d_loss.item():.4f}, G_Loss: {g_loss.item():.4f}\")\n",
        "\n",
        "    # Pertes moyennes\n",
        "    avg_d_loss = epoch_d_loss / len(dataloader)\n",
        "    avg_g_loss = epoch_g_loss / len(dataloader)\n",
        "    print(f\"\\n=> Fin de l'époque [{epoch+1}/{num_epochs}] - D_Loss: {avg_d_loss:.4f}, G_Loss: {avg_g_loss:.4f}\\n\")\n",
        "\n",
        "    # Sauvegarde des logs\n",
        "    with open(log_file, 'a') as f:\n",
        "        f.write(f\"{epoch+1}\\t{avg_d_loss:.4f}\\t{avg_g_loss:.4f}\\n\")\n",
        "\n",
        "    # Sauvegarde d'un modèle 3D généré\n",
        "    sample_voxel = fake_voxels[0]\n",
        "    obj_path = os.path.join(output_dir, f'generated_model_epoch_{epoch+1}.obj')\n",
        "    save_as_obj(sample_voxel, obj_path)\n",
        "\n",
        "    print(f\"Modèle 3D sauvegardé : {obj_path}\")\n",
        "    print(f\"Logs mis à jour dans {log_file}\")\n",
        "\n",
        "# Sauvegarde de l'état final du modèle générateur\n",
        "generator_model_path = os.path.join(output_dir, 'generator_final.pth')\n",
        "torch.save(G.state_dict(), generator_model_path)\n",
        "print(f\"L'état du modèle générateur a été sauvegardé à : {generator_model_path}\")"
      ],
      "metadata": {
        "id": "K4NrkV63rOB9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74659901-876a-4442-ea6a-55bb9819e225"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Époque 1/50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Utilisation du générateur sauvegardé pour la génération**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "### Pour utiliser le modèle générateur sauvegardé, chargez son état avec `torch.load` et générez un nouveau modèle 3D.\n",
        "\n",
        "### Code pour charger le générateur et générer un modèle"
      ],
      "metadata": {
        "id": "Sk3xxEZDrQEN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Charger le modèle générateur sauvegardé\n",
        "G_loaded = Generator().to(device)\n",
        "G_loaded.load_state_dict(torch.load(generator_model_path))\n",
        "G_loaded.eval()  # Mettre le modèle en mode évaluation\n",
        "\n",
        "# Exemple de génération avec une nouvelle image\n",
        "def generate_3d_model(image_path, generator, output_path):\n",
        "    \"\"\"\n",
        "    Génère un modèle 3D à partir d'une image 2D et le sauvegarde en .obj.\n",
        "    :param image_path: Chemin de l'image d'entrée.\n",
        "    :param generator: Modèle générateur chargé.\n",
        "    :param output_path: Chemin pour sauvegarder le fichier .obj généré.\n",
        "    \"\"\"\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Resize((128, 128)),\n",
        "        transforms.Normalize((0.5,), (0.5,))\n",
        "    ])\n",
        "    image = plt.imread(image_path)\n",
        "    image = transform(image).unsqueeze(0).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        generated_voxel = generator(image)\n",
        "        save_as_obj(generated_voxel, output_path)\n",
        "\n",
        "# Générer un modèle 3D avec une nouvelle image\n",
        "new_image_path = '/content/pix3d/img/bed/0001.png'\n",
        "output_3d_path = './generated_new_model.obj'\n",
        "generate_3d_model(new_image_path, G_loaded, output_3d_path)\n",
        "print(f\"Modèle 3D généré et sauvegardé à : {output_3d_path}\")\n"
      ],
      "metadata": {
        "id": "29fP2o49raQu"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}